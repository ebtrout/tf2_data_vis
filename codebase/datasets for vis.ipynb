{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fdd984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from better_profanity import profanity\n",
    "import numpy as np\n",
    "\n",
    "players = pd.read_csv(\"../data/players.csv\")\n",
    "\n",
    "player_rounds = pd.read_csv(\"../data/player_rounds.csv\")\n",
    "\n",
    "valid_ids = pd.read_csv(\"../data/valid_ids.csv\")\n",
    "\n",
    "push_stats = pd.read_csv(\"../data/push_stats.csv\")\n",
    "\n",
    "teams = pd.read_csv(\"../data/teams.csv\")\n",
    "\n",
    "healspread = pd.read_csv(\"../data/healspread.csv\")\n",
    "\n",
    "info = pd.read_csv(\"../data/info.csv\")\n",
    "\n",
    "round_events = pd.read_csv('../data/round_events.csv')\n",
    "\n",
    "model_ready_data = joblib.load(\"../data/pkls/model_ready_data_dict.pkl\")\n",
    "X = model_ready_data['X']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c803b66f",
   "metadata": {},
   "source": [
    "* Valid map names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd647b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find valid map names\n",
    "info_correct = info[info['id'].isin(model_ready_data['ids'])].copy()\n",
    "maps = info_correct['map'].str.lower().str.split(\"_\")\n",
    "map_counts = pd.Series(maps.str[1].value_counts())\n",
    "\n",
    "\n",
    "valid_maps = map_counts[map_counts > 50]\n",
    "valid_map_names = valid_maps.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf7a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_info = info[info['id'].isin(valid_ids['id'])].copy()\n",
    "\n",
    "map_names = list(valid_info['map'].str.lower().str.split(\"_\").str[1].value_counts().index)\n",
    "\n",
    "map_counts = []\n",
    "for map in info['map'].str.lower().values:\n",
    "    i = 0\n",
    "    for map_name in map_names:\n",
    "        if i > 0:\n",
    "            continue\n",
    "        if  type(map) == type(np.nan):\n",
    "            map_counts.append(np.nan)\n",
    "            i +=1\n",
    "        elif map_name in map:\n",
    "            map_counts.append(map_name)\n",
    "            i += 1\n",
    "        \n",
    "\n",
    "# Define a function to find the first match\n",
    "def find_match(text):\n",
    "    if type(text) == type(np.nan):\n",
    "        return np.nan\n",
    "    for keyword in map_names:\n",
    "        if keyword in text.lower():\n",
    "            return keyword\n",
    "    return np.nan  # if no match found\n",
    "\n",
    "# Apply the function row by row\n",
    "info['clean_map_name'] = info['map'].apply(find_match)\n",
    "valid_info['clean_map_name'] = valid_info['map'].apply(find_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef54a19",
   "metadata": {},
   "source": [
    "* Koth stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b1444",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_info = info[info['id'].isin(valid_ids['id'].values)]\n",
    "koth = valid_info.copy()\n",
    "koth = valid_info[valid_info['map'].str.split(\"_\").str[0].str.contains(\"koth\")]\n",
    "koth_count = koth['map'].str.lower().str.split(\"_\")\n",
    "koth_count = pd.Series(koth_count.str[1].value_counts())\n",
    "koth_count = koth_count[koth_count > 50]\n",
    "koth_maps = koth_count.index.values\n",
    "koth_matches = info[info['clean_map_name'].isin(koth_maps)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffbc217",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_caps = round_events[\n",
    "    (round_events['type'] == 'pointcap') | (round_events['type'] == 'round_win')\n",
    "].copy()\n",
    "\n",
    "match_round_list = []\n",
    "\n",
    "for i,match_id in enumerate(koth_matches['id'].unique()):\n",
    "    #if i % 100 == 0 and i != 0:\n",
    "        #print(f'{i} / {koth_matches['id'].nunique()}')\n",
    "    df = point_caps[point_caps['id'] == match_id].copy()\n",
    "\n",
    "    for round_num in df['round'].unique():\n",
    "        match_round = df[df['round'] == round_num].copy()\n",
    "\n",
    "        # Compute lag_time and time_elapsed per group (team) using shift(-1)\n",
    "        match_round['lag_time'] = match_round.groupby('team')['time'].shift(-1)\n",
    "        match_round['time_elapsed'] = match_round['lag_time'] - match_round['time']\n",
    "        match_round['time_elapsed'] = match_round['time_elapsed'].fillna(0)\n",
    "\n",
    "        # Calculate total cap time per round and team\n",
    "        cap_time_df = match_round.groupby(['round', 'team'])['time_elapsed'].sum().reset_index()\n",
    "        cap_time_df.rename(columns={'time_elapsed': 'cap_time'}, inplace=True)\n",
    "        match_round = match_round.merge(cap_time_df, on=['round', 'team'], how='left')\n",
    "\n",
    "        # Number of caps per round and team\n",
    "        num_caps = match_round[match_round['type'] == 'pointcap'].groupby(['round', 'team']).size().reset_index(name='num_caps')\n",
    "        match_round = match_round.merge(num_caps, on=['round', 'team'], how='left')\n",
    "        match_round['num_caps'] = match_round['num_caps'].fillna(0).astype(int)\n",
    "\n",
    "        # Rolling cap times per team (cumulative sum of time_elapsed per team)\n",
    "        match_round['blue_cap_time'] = match_round.apply(lambda row: row['time_elapsed'] if row['team'] == 'Blue' else 0, axis=1).cumsum()\n",
    "        match_round['red_cap_time'] = match_round.apply(lambda row: row['time_elapsed'] if row['team'] == 'Red' else 0, axis=1).cumsum()\n",
    "\n",
    "        # Winner for the round\n",
    "        winners = match_round.loc[match_round['type'] == 'round_win', 'team']\n",
    "        winner = winners.values[0] if not winners.empty else np.nan\n",
    "        match_round['winner'] = winner\n",
    "\n",
    "        # Roll condition\n",
    "        red_cap_sum = match_round['red_cap_time'].sum()\n",
    "        blue_cap_sum = match_round['blue_cap_time'].sum()\n",
    "        if red_cap_sum == 0 and winner == 'Blue':\n",
    "            match_round['roll'] = 1\n",
    "        elif blue_cap_sum == 0 and winner == 'Red':\n",
    "            match_round['roll'] = 1\n",
    "        else:\n",
    "            match_round['roll'] = 0\n",
    "\n",
    "        # Comeback condition\n",
    "        cond1 = (match_round['winner'] == 'Red') & (match_round['red_cap_time'] == 0) & (match_round['blue_cap_time'] >= 150)\n",
    "        cond2 = (match_round['winner'] == 'Blue') & (match_round['blue_cap_time'] == 0) & (match_round['red_cap_time'] >= 150)\n",
    "        if (cond1 | cond2).any():\n",
    "            match_round['comeback'] = 1\n",
    "        else:\n",
    "          match_round['comeback'] = 0\n",
    "\n",
    "        match_round_list.append(match_round)\n",
    "\n",
    "koth_stats = pd.concat(match_round_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d36a6e",
   "metadata": {},
   "source": [
    "* Make PIM bindable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e6a9dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in\n",
    "players_wide = model_ready_data['players_wide']\n",
    "PIM = pd.read_csv(\"../data/PIM_X.csv\")\n",
    "X = model_ready_data['X']\n",
    "teams = pd.read_csv(\"../data/teams.csv\")\n",
    "\n",
    "\n",
    "### GET PLAYER CLASS NAMES TO BE STEAMID + SCOUT1 / SOLDIER2 / DEMO\n",
    "# Melt columns together to make a long dataset\n",
    "cols = ['id','team'] + [col for col in players_wide.columns if \"steamid\" in col]\n",
    "player_classes = players_wide[cols].copy()\n",
    "player_class_long = player_classes.melt(id_vars=['id', 'team'], \n",
    "                  var_name='class', \n",
    "                  value_name='steamiplayers_wided')\n",
    "\n",
    "# Make temp columns to transform \n",
    "player_class_long['class_clean'] = player_class_long['class'].str.split(\"_\").str[0]\n",
    "player_class_long['temp'] = player_class_long['class'].str.split(\"_\").str[1]\n",
    "\n",
    "# Fix up class name to be scout1 soldier2 instead of just scout soldier\n",
    "class_list = []\n",
    "for i,name in enumerate(player_class_long['class_clean']):\n",
    "    if name == 'scout' or name == 'soldier':\n",
    "        name += player_class_long.loc[i,'temp']\n",
    "    class_list.append(name)\n",
    "player_class_long['class'] = class_list\n",
    "player_class_long.drop(['class_clean','temp'],axis = 1,inplace = True)\n",
    "\n",
    "\n",
    "### MAKE PIM BINDABLE\n",
    "PIM['id'] = X['id'].values\n",
    "\n",
    "\n",
    "PIM_long = PIM.melt(\n",
    "    id_vars=['id', 'winner'],\n",
    "    var_name='class',\n",
    "    value_name='PIM'\n",
    ")\n",
    "\n",
    "# Make pim_long\n",
    "teams_pim = teams[['id','team','winner']].copy()\n",
    "PIM_long = PIM_long.merge(teams_pim,on = ['id','winner'],how = \"left\")\n",
    "PIM_long = PIM_long.merge(player_class_long,on = ['id','team','class'],how = 'left')\n",
    "PIM_long.rename(columns={\"steamiplayers_wided\":\"steamid\"},inplace = True)\n",
    "\n",
    "PIM_long.to_csv(\"../data/PIM_X.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addc213e",
   "metadata": {},
   "source": [
    "* Clean map name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c073a8",
   "metadata": {},
   "source": [
    "### Player Overview Tables ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f68e7d",
   "metadata": {},
   "source": [
    "* Basic Stats Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1dd2456",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_cols = ['kills','deaths','assists','dmg','dmg_real','dt','dt_real','hr']\n",
    "pct_cols = ['kill_pct','deaths_pct','assists_pct','dmg_pct','dmg_real_pct','dt_pct','dt_real_pct','hr_pct']\n",
    "\n",
    "both_cols = ['id','team','steamid','name','primary_class']\n",
    "\n",
    "normal_df = players[both_cols + normal_cols].copy()\n",
    "pct_df = players[both_cols + pct_cols].copy()\n",
    "\n",
    "pct_df.columns = normal_df.columns\n",
    "\n",
    "normal_df['coltype'] = \"Raw\"\n",
    "pct_df['coltype'] = \"Pct of Team\"\n",
    "\n",
    "\n",
    "long_player = pd.concat([normal_df,pct_df])\n",
    "\n",
    "long_player = long_player.fillna(0)\n",
    "\n",
    "long_player.to_csv(\"../data/long_player_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3aeaf3",
   "metadata": {},
   "source": [
    "* Class KDA Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cebfc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_cols = [col for col in players.columns if \"class_kda\" in col]\n",
    "\n",
    "class_kill = [col for col in class_cols if \"kills\" in col and \"kdapd\" not in col]\n",
    "\n",
    "class_deaths= [col for col in class_cols if \"deaths\" in col and \"kdapd\" not in col]\n",
    "\n",
    "class_assists = [col for col in class_cols if \"assists\" in col and \"kdapd\" not in col]\n",
    "\n",
    "class_kill_pd = [col for col in class_cols if \"kills\" in col and \"kdapd\" in col]\n",
    "\n",
    "class_deaths_pd = [col for col in class_cols if \"deaths\" in col and \"kdapd\" in col]\n",
    "\n",
    "class_assists_pd = [col for col in class_cols if \"assists\" in col and \"kdapd\" in col]\n",
    "\n",
    "keep_cols = ['id','team','steamid','name','primary_class']\n",
    "\n",
    "\n",
    "\n",
    "class_dict = {\n",
    "    \"Kills\" : class_kill,\n",
    "    \"Deaths\" : class_deaths,\n",
    "    \"Assists\" : class_assists,\n",
    "    \"K/D\" : class_kill_pd,\n",
    "    \"A/D\" : class_assists_pd,\n",
    "    \"Death Rate\" : class_deaths_pd\n",
    "}\n",
    "\n",
    "long_class = pd.DataFrame()\n",
    "for key in class_dict.keys():\n",
    "    col_type = key\n",
    "    l = class_dict[key]\n",
    "    df = players[keep_cols + l].copy()\n",
    "    df.columns = keep_cols + [col.split(\"_\")[0] for col in df.columns if col not in keep_cols] \n",
    "    df['col_type'] = col_type\n",
    "    long_class = pd.concat([long_class,df])\n",
    "\n",
    "long_class = long_class.fillna(0)\n",
    "\n",
    "long_class.to_csv(\"../data/class_kda_long.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bf2e27",
   "metadata": {},
   "source": [
    "* Quantile Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6293ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List out columns\n",
    "quant_cols = [\n",
    "    \"kills\",\n",
    "    \"assists\",\n",
    "    \"dmg\",\n",
    "   'dapm',\n",
    "   'kpd',\n",
    "   'offclass_pct',\n",
    "   'kill_pct',\n",
    "   'deaths_pct',\n",
    "   'dmg_pct',\n",
    "   'dmg_real_pct',\n",
    "   'cpc_pct',\n",
    "   'ka_pct',\n",
    "   'assists_pct',\n",
    "   'dt_pct',\n",
    "   'dt_real_pct',\n",
    "   'hroi',\n",
    "   'assistspd',\n",
    "   'demoman_kills_class_kdapd',\n",
    "   'scout_kills_class_kdapd',\n",
    "   'soldier_kills_class_kdapd',\n",
    "   'medic_kills_class_kdapd',\n",
    "    'demoman_deaths_class_kdapd',\n",
    "   'scout_deaths_class_kdapd',\n",
    "   'soldier_deaths_class_kdapd',\n",
    "    'medic_deaths_class_kdapd',\n",
    "   'dtpm',\n",
    "   'dt_realpm',\n",
    "   'healpm',\n",
    "   'medkits_hppm', \n",
    "   'hrpm', \n",
    "   'deathspm'\n",
    "\n",
    "]\n",
    "\n",
    "# Only grab valid ids to make quanitles on\n",
    "sub_players = players[players['id'].isin(valid_ids['id'])].copy()\n",
    "sub_players = sub_players[['id',\"primary_class\",'steamid']+ quant_cols]\n",
    "\n",
    "# loop through classes and construct the quantile sets\n",
    "ranked_df = pd.DataFrame()\n",
    "for class_name in sub_players['primary_class'].unique():\n",
    "    sub_class = sub_players[sub_players['primary_class'] == class_name].copy()\n",
    "    \n",
    "    binding_df = sub_class[['id',\"primary_class\",'steamid']].copy()\n",
    "    sub_class.drop(['id',\"primary_class\",'steamid'],axis = 1,inplace= True)\n",
    "    \n",
    "    sub_class = sub_class.rank(pct = True)\n",
    "    sub_class = pd.concat([binding_df,sub_class],axis = 1)\n",
    "    \n",
    "    ranked_df = pd.concat([ranked_df,sub_class])\n",
    "    \n",
    "# Rename columns\n",
    "ranked_df.columns = ['id','primary_class','steamid'] + [col + '_quantile' for \n",
    "                                                        col in ranked_df.columns if\n",
    "                                                        col not in ['id','steamid','primary_class']]\n",
    "\n",
    "ranked_df.to_csv(\"../data/players_quantile.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
